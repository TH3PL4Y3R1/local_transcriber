# Project configuration for local transcriber & summarizer
chunk_size: 120  # seconds, 2 minutes per chunk for better context
whisper_model: medium  # use 'medium' for good balance of speed and accuracy; try 'large' if you want best accuracy and have enough VRAM
llm_model: Mistral-7B-Instruct-v0.3-Q5_K_M.gguf
# Set default language for transcription
whisper_language: es
input_dir: audio_input
chunks_dir: audio_chunks
transcripts_dir: transcripts
summaries_dir: summaries
models_dir: models
